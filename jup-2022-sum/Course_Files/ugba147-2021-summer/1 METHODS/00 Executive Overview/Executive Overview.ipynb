{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Overview\n",
    "\n",
    "![](banner_exec.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science for Business\n",
    "\n",
    "When making a business decision, you can guess about what happened in the past, is happening now, or will happen in the future.  You can then decide what to do based on your guess.  You will consequently get a business result that comes about from your decision.  You might assume that when your guesses are based on patterns you see in some relevant data, then your guesses will be better, and so your decisions will be better, and so the business results will be better.  Indeed, this is often the case.  Challenges arise, however, when the patterns in data are difficult to detect.\n",
    "\n",
    "**Data science for business** combines statistics and computing to find patterns in data that would be otherwise not easy to detect, so that you can make good guesses, so that you can make good decisions, so that you will more often get good business results. \n",
    "\n",
    "Data science for business enables you to find and quantify answers to questions like these:\n",
    "* What are the patterns in the data?\n",
    "* What guess can be made from these patterns?\n",
    "* What are the probabilities that the guess is right or wrong, and what are the probabilities that the guess is wrong in any of several different ways?\n",
    "* What decision best leverages the guess and the probabilities of how the guess could be right or wrong?\n",
    "* What is the probability that a decision leads to a good business result, and what are the probabilities that it leads to any of several other different business results?\n",
    "\n",
    "\n",
    "_Consider a business manager in charge of, say, a manufacturing process.  This business manager must decide how many workers to schedule based on a guess about what the demand for the company’s product this month will be.  Demand three months ago was 1 million units, two months ago was 2 million units, and last month was 4 million units.  Here are three ways the business manager could make a decision:_\n",
    "\n",
    "* _**Decision (not based on data):**  Our business manager decides to keep the current number of workers, which is enough to manufacture 4 million units._\n",
    "* _**Data-Driven Decision:**  One pattern easily seen in these data is that demand has been doubling every month.  So, our business manager guesses demand this month will be 8 million units.  From there, our business manager decides to schedule enough workers to manufacture 8 million units._\n",
    "* _**Data-Driven Decision Using Business Analytics:**  Our business manager considers much richer data, which includes information about more than just recent demand.  Patterns in such rich data are difficult to detect, but our business manager applies various methods that do find them.  Based on these patterns, our business manager guesses that the demand this month will be 6 million units, but further knows that there is a 30% probability it could be higher and a 10% probability it could lower, and that the consequences of understaffing could cost the company up to \\\\$1 million in lost opportunity and overstaffing could cost the company more than \\\\$2 million in unnecessary worker costs.  Our business manager considers these and other factors, and decides to schedule enough workers to manufacture 7 million units._ \n",
    "\n",
    "_In all three cases, the business result will depend on what the demand actually turns out to be, but we assume that the data-driven decision using business analytics will most likely lead to the best business result._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-to-Decision Methodology\n",
    "\n",
    "The **data-to-decision methodology** prescribes a way to make data-driven decisions by iteratively working through three stages of data analysis:\n",
    "\n",
    "* **Data management** involves gathering, storing, and retrieving data for eventual use in decision making.<br><br>\n",
    "\n",
    "* **Exploratory data analysis (EDA)** involves representing data in various ways and applying methods to expose patterns that may lead to non-obvious insights useful in decision making.<br><br>\n",
    "\n",
    "* **Modeling** involves applying methods to further expose patterns in the data by estimating the underlying processes responsible for generating the data.  Such models may make predictions that reveal non-obvious insights useful in decision making.  \n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px\">\n",
    "    <caption style=\"text-align:center\">The Data-to-Decision Methodology</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"d2d_process.jpg\"></td></tr>\n",
    "</table><br clear=all>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Decision Models\n",
    "\n",
    "A **decision model** estimates business results that would come about from various decisions informed by a business model, business parameter values, and data analytic models.\n",
    "\n",
    "A **business model** describes how a business converts products and services to money.\n",
    "\n",
    "**Business parameters** detail various aspects of a business's operating environment.\n",
    "\n",
    "A decision model can be conveniently expressed as an **influence diagram**, useful for communicating assumptions upon which the model is based.  An influence diagram comprises symbols for a decision, performance metrics associated with a data analytic model, business parameters, intermediate calculations, and a business result, with dependencies among these shown as directed links. \n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px; margin-bottom:20px\">\n",
    "    <caption style=\"text-align:center\">Example of a Decision Model Represented as an Influence Diagram</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"decision_model.jpg\" width=600></td></tr>\n",
    "</table><br clear=all>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analytic Models\n",
    "\n",
    "**Artificial intelligence (AI)** is about machines doing things that you would normally expect only humans could do.  One way a machine could do these things is by following formulae developed by the machine itself from patterns it finds in data – that’s a **data analytic model**.  The process of constructing a data analytic model is called **machine learning (ML)** or **training a model**, and employs a variety of **methods**.\n",
    "\n",
    "One kind of data analytic model specifies how to partition data into clusters - that's a **cluster model**. It could be constructed using an **unsupervised method**, so called because an unsupervised method does not make use of examples of correct partitions.\n",
    "\n",
    "Another kind of data analytic model specifies how to predict as yet unobserved examples not explicitly reflected in data – that's a **predictive model**.  It could be constructed using a **supervised method**, so called because a supervised method makes use of examples of correct predictions. A predictive model that predicts categorical values is called a **classifier**, the categorical values it predicts are called **classes**, and a method to construct it is called a **classifier construction method**.  A predictive model that predicts numeric values is called a **regressor**, the numeric values it predicts are called **outcomes**, and a method to construct it is called a **regressor construction method**.\n",
    "\n",
    "Another kind of data analytic model specifies connection relationships between entities - that's a **social network model**.\n",
    "\n",
    "A method comprising a combination of several other methods working in concert is called an **ensemble method**.\n",
    "\n",
    "Any particular model construction method is defined by its general approach and its specific **hyper-parameter** values.  Any particular model, constructed by a method, is defined by its general form and its specific **parameter** values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Management Methods\n",
    "\n",
    "In practice, there are a vast number of methods to address the complexities around gathering, storing, and retrieving data.  Here we are interested primarily in simple **data retrieval** to ready data for exploratory data analysis and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis Methods\n",
    "\n",
    "\n",
    "### Data Exploration\n",
    "\n",
    "After a dataset is retrieved and perhaps in response to transforming its representation, it may be useful to to look for patterns in the data that can produce insights and inform decisions.  This is **data exploration**.\n",
    "\n",
    "**Data extraction** involves the mechanics of slicing and dicing data to get at just a subset of interest, which could include a subset of observations and/or a subset of variables, arranged in various ways. \n",
    "\n",
    "A **descriptive statistic** is a number that conveniently summarizes some data, specifically one or more variable distributions.  Here  are some popular descriptive statistics:\n",
    "size ($N$, $n$);\n",
    "probability, also known as relative frequency or proportion ($P$);\n",
    "arithmetic mean, also known as mean or average ($\\mu$, $\\bar{x}$);\n",
    "geometric mean;\n",
    "median;\n",
    "variance ($\\sigma^2$, $s^2$);\n",
    "standard deviation ($\\sigma$, $s$);\n",
    "percentile;\n",
    "weighted average;\n",
    "correlation coefficient ($r$).\n",
    "\n",
    "A **cross-tabulation** is a table that conveniently summarizes some data, organized by rows and columns that correspond to variable values, and aggregated by various functions like mean, sum, or count. \n",
    "\n",
    "A **data visualization** is a graphic representation of some data, specifically one or more variable distributions.  Here are some popular data visualizations:\n",
    "\n",
    "* A **scatterplot** of data shows distributions of some numeric variables represented by points positioned along axes, and perhaps distributions of other categorical variables represented by color, size, shape, or pattern.<br><br>\n",
    "\n",
    "* A **scatterplot projection** of data is a scatterplot with 3 axes, projected onto a flat surface.<br><br>\n",
    "\n",
    "* A **lineplot** of data shows distributions of some numeric variables represented by points positions along axes, and further relationships between data represented by line segments connecting the points, and perhaps distributions of other categorical variables represented by color, size, shape, or pattern.<br><br>\n",
    "\n",
    "* A **barplot** of data shows the distribution of a categorical variable represented by heights of adjacently positioned bars, and perhaps distributions of other categorical variables represented by color or pattern.<br><br> \n",
    "\n",
    "* A **histogram** of data shows counts of particular ranges of values in the distribution of a numeric variable represented by heights of adjacently positioned bars.<br><br>\n",
    "\n",
    "* A **density plot** of data shows an estimated proportion of values within any range of a numeric variable represented by the area under a curve.  The **kernel density estimation (KDE)** method is one way to produce a density plot.<br><br>\n",
    "\n",
    "* An **animation** of data shows the distribution of a variable, often indicating time, represented by a sequence of other data visualizations. \n",
    "\n",
    "\n",
    "\n",
    "### Data Representation\n",
    "\n",
    "After a dataset is retrieved and perhaps in response to data exploration, it may be useful to transform its representation so that various methods can be applied or made more effective.  This is **data representation**.  Here are some popular data representation transformation methods: \n",
    "\n",
    "* Transformation by **synthesizing** data adds new variables whose values are constructed based only on information already captured in the original data.   \n",
    "\n",
    "\n",
    "* Transformation by **imputing** data fills in missing values with synthetic values, often based on descriptive statistics. \n",
    "\n",
    "\n",
    "* Transformation by **balancing** data duplicates or removes observations to make a particular categorical variable distribution reflect equal numbers of each possible value.  \n",
    "\n",
    "\n",
    "* Transformation by **aligning** data expands or contracts observations to make a particular variable distribution match another dataset's particular variable distribution, often indicating time.\n",
    "\n",
    "\n",
    "* The **principal component analysis** method applied to a dataset synthesizes a set of new variables, called **principal components**, that capture in entirety the same relationships between data as do the original variables, but concentrate variance disproportionately in just the first few of the new variables.  Transformation to principal components replaces the original variables with the principal components.\n",
    "\n",
    "\n",
    "### Data Representation of Special Data Types\n",
    "\n",
    "Many data analytic methods cannot be applied directly to text, time series, or social network data because of their special representations.  Often, though, data analytic methods can be applied to such data transformed to an appropriate alternative representation.   \n",
    "\n",
    "\n",
    "* **Text data** can be transformed to **document-term matrix** form, where observations correspond to documents and variables correspond to occurrences of words.  Data analytic methods can then be applied as usual.\n",
    "\n",
    "\n",
    "* **Time series data** can be transformed to **cross-sectional data**, where observations correspond to points in time and include variables with information about points in time past called **lookbacks** and points in time future called **lookaheads**.  Data analytic methods can then be applied to forecast by **direct prediction** some number of time steps ahead of a **viewpoint**, or by **recursive prediction** one timestep ahead of previous predictions.\n",
    "\n",
    "\n",
    "* **Social network data** is often represented in a special form like an **adjacency matrix** or **link list**, and analysis requires special descriptive statistics, like **PageRank** used in the Google ranking algorithm.  Recommender systems based on **collaborative filtering** work on **bipartite graphs**, a special version of social network data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Methods\n",
    "\n",
    "### Cluster Model Construction\n",
    "\n",
    "A **cluster model construction method** examines data and organizes observations into several classes.  Such an organization is called a **cluster model**, and can be useful for decisions involving market segmentation and other business applications. \n",
    "\n",
    "Here are some popular cluster model construction methods:\n",
    "\n",
    "* The **Gaussian mixture model by expectation-maximization** method constructs models by assigning observations partial membership in all possible classes and then iteratively concentrating membership in the most expected classes.<br><br>\n",
    "\n",
    "* The **hierarchical agglomeration** method constructs models by agglomerating observations into classes based on their dissimilarity to other observations.<br><br>\n",
    "\n",
    "* The **k-means** method constructs models by tentatively organizing observations into several classes and then iteratively improving the organization based on the observations dissimilarity to other observations.\n",
    "\n",
    "Popular ways to measure dissimilarity between observations comprising all numeric variables include **Manhattan distance**, **Euclidean distance**, **cosine distance**, and others.  Measures of dissimilarity between clusters are calculated assuming some **linkage**, which can be **single**, **complete**, **centroid**, or **average** linkage.\n",
    "\n",
    "\n",
    "\n",
    "### Predictive Model Construction: Binary Classifiers\n",
    "\n",
    "A **binary classifier construction method** examines data to construct a predictive model capable of estimating the probabilities that new observations should be classified as members of one class or another class.  From these probabilities, taken along with some chosen cutoff threshold, you can predict whether the new observations should be classified as members of one class or another class.  Such a predictive model is called a **binary classifier**, or often just a **classifier**.\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px\">\n",
    "    <caption style=\"text-align:center\">Construct a Classifier</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"classification_train.jpg\" width=440></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px; margin-bottom:20px\">\n",
    "    <caption style=\"text-align:center\">Use a Classifier to Make Predictions</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"classification_predict.jpg\" width=560></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "Here are some popular binary classifier construction methods:\n",
    "\n",
    "* The **naïve Bayes** method constructs models based on probabilities and conditional probabilities of values appearing in the data.  **LaPlace smoothing** is a technique incorporated into the naïve Bayes method that may improve its models’ predictions.  Hyper-parameters include LaPlace smoothing factor and others.<br><br>\n",
    "\n",
    "* The **support vector machine (SVM)** method constructs models based on an optimal separation of observations in variable space.  Hyper-parameters include cost, kernel, and others.<br><br>\n",
    "\n",
    "* The **neural network** method (classification version) constructs models based on how values appearing in the data can be combined as they propagate throughout a network structure.  This method is inspired by, but different from, how biological brain neurons communicate with each other.  Hyper-parameters include number of levels, number of nodes in each level, and others.  The **perceptron** method is a simplified version of the neural network method.  **Deep learning** refers to constructing models using the neural network method.<br><br>\n",
    "\n",
    "* The **logistic regression** method constructs models based on the optimal S-shaped hyper-curve through observations in variable space.<br><br>\n",
    "\n",
    "* The **decision tree (DT)** method (classification version) constructs models based on the optimal splitting of the data into progressively smaller sets of data.  Hyper-parameters include maximum depth of tree, maximum number of nodes, and others.<br><br>\n",
    "\n",
    "* The **nearest neighbor (kNN)** method (classification version) constructs models based on how similar observations are to each other.  Hyper-parameters include number of nearest neighbors and others.  Measures of dissimilarity can be Manhattan distance, Euclidean distance, cosine distance, or others.\n",
    "\n",
    "\n",
    "### Predictive Model Construction: Multinomial Classifiers\n",
    "\n",
    "A **multinomial classifier construction method** is a generalization of a binary classifier construction method, which constructs a predictive model capable of estimating the probabilities that new observations should be classified as members of any of several classes.  Such a predictive model is called a **multinomial classifier**, or often just a **classifier**.\n",
    "\n",
    "Here are some popular classifier construction methods that have both binary and multinomial forms:\n",
    "\n",
    "* naïve Bayes\n",
    "* neural network\n",
    "* decision tree\n",
    "* nearest neighbor\n",
    "\n",
    "Any binary classifier can be converted to a multinomial classifier with either of two binary-to-multinomial conversion methods: \n",
    "\n",
    "* The **one-versus-one** method reorganizes a dataset into several other datasets, one for each class versus all other classes treated as a single other class.  Models are constructed based on all these datasets, and predictions are made by majority rule or cutoff among the models.<br><br>\n",
    "\n",
    "* The **one-versus-many** method reorganizes a dataset into several other datasets, one for each pair of classes, excluding the other classes.  Models are then constructed based on these datasets, and prediction are made by a round robin tournament among the models.\n",
    "\n",
    "\n",
    "### Predictive Model Construction: Regressors\n",
    "\n",
    "A **regressor construction method** examines data to construct a predictive model capable of predicting which numeric values be associated with new observations.  Such a predictive model is called a **regressor**.\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px\">\n",
    "    <caption style=\"text-align:center\">Construct a Regressor</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"regression_train.jpg\" width=440></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px; margin-bottom:20px\">\n",
    "    <caption style=\"text-align:center\">Use a Regressor to Make Predictions</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"regression_predict.jpg\" width=380></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "Here are some popular regressor construction methods:\n",
    "\n",
    "* The **linear regression** method constructs models based on the optimal line, plane, or hyper-plane fitted through observations in variable space.<br><br>\n",
    "\n",
    "* The **support vector regression (SVR)** method constructs models based on an optimal separation of observations in variable space.  Hyper-parameters include cost, kernel, and others.<br><br>\n",
    "\n",
    "* The **neural network** method (regression version) constructs models based on how values appearing in the data can be combined as they propagate throughout a network structure.  This method is inspired by, but different from, how biological brain neurons communicate with each other.  Hyper-parameters include number of levels and number of nodes in each level.  **Deep learning** refers to constructing models using the neural network method.<br><br>\n",
    "\n",
    "* The **decision tree (DT)** method (regression version) constructs models based on the optimal splitting of the data into progressively smaller sets of data.  Hyper-parameters include maximum depth of tree, maximum number of nodes, and others.<br><br>\n",
    "\n",
    "* The **nearest neighbor (kNN)** method (regression version) constructs models based on how similar observations are to each other.  Hyper-parameters include number of nearest neighbors and others.  Measures of dissimilarity can be Manhattan distance, Euclidean distance, cosine distance, or others.<br><br>\n",
    " \n",
    "Some regressor construction methods involve finding optimal solutions to various formulae, using search algorithms like **gradient descent** or others.\n",
    "\n",
    "\n",
    "### Predictive Model Construction: Ensembles\n",
    "\n",
    "An **ensemble method** combines several predictive models working in concert to construct a predictive model with benefits derived from all the component methods.\n",
    "\n",
    "Here are some popular ensemble methods to construct classifiers or regressors:\n",
    "\n",
    "* The **bootstrap aggregating (bagging)** ensemble method constructs models based on a single component method, but on several random subsets of data.  You can think of the result as a committee of experts.<br><br>\n",
    "\n",
    "* The **boosting** ensemble method constructs models based on a single component method, but on several random subsets of data, where each subset emphasizes observations predicted incorrectly by other models.  You can think of the result as a committee of experts, each member with increasingly specialized knowledge.<br><br>\n",
    "\n",
    "* The **stacking** ensemble method constructs models based on several component methods, and on the predictions made by models constructed using those component methods.  You can think of the result as a committee of experts on other experts.<br><br>\n",
    "\n",
    "* The **random forest** method is a variation on bootstrap aggregating.  It uses decision tree as the single component method, uses several random subsets of data, and also uses several randomly selected variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Methods\n",
    "\n",
    "### Cluster Model Evaluation\n",
    "\n",
    "Popular cluster model performance metrics include **dispersion ratio**, **Bayes information criterion (BIC)**, **Akaike information criterion (AIC)**, and others.  Each of these reflect the average dissimilarity between observations within a cluster and the average dissimilarity between clusters.\n",
    "\n",
    "\n",
    "### Predictive Model Evaluation\n",
    "<br>\n",
    "\n",
    "\n",
    "#### Sampling for Predictive Model Evaluation\n",
    "\n",
    "Here are three popular methods to evaluate predictive model performance:\n",
    "\n",
    "**In-sample** performance evaluation of a model constructed from all the data works like this:<br>\n",
    "Use the model to predict the classes/outcomes of the data, and compare those predictions to the known actual classes/outcomes based on some performance metric.  This method has the advantage that the model is constructed from all the data, but has the disadvantage that predictions are about data already known to the model.\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px\">\n",
    "    <caption style=\"text-align:center\">In-sample Evaluation of a Classifier</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"classification_insample.jpg\" width=750></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px; margin-bottom:20px\">\n",
    "    <caption style=\"text-align:center\">In-sample Evaluation of a Regressor</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"regression_insample.jpg\" width=750></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "**Out-of-Sample** performance evaluation of a model constructed from all the data works like this:<br>\n",
    "Construct a new model from a subset of all the data (referred to as **training data**) to predict the classes/outcomes of the remaining data (referred to as **validation data**), and then compare those predictions to the known actual classes/outcomes based on some performance metric.  The new model is constructed using the same method and hyper-parameter values as for the model to be evaluated, but using different data.  It is assumed that the new model has performance closely approximating that of the model to be evaluated.  This method is also known as **holdout** performance evaluation.  This method has the disadvantage that the new model is constructed from only some of the data, but has the advantage that predictions are about data not known to the model.\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px\">\n",
    "    <caption style=\"text-align:center\">Out-of-Sample Evaluation of a Classifier</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"classification_outofsample.jpg\" width=950></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px; margin-bottom:20px\">\n",
    "    <caption style=\"text-align:center\">Out-of-Sample Evaluation of a Regressor</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"regression_outofsample.jpg\" width=950></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "**Cross-validation** performance evaluation of a model constructed from all the data works like this:<br>\n",
    "Partition the data into subsets called **folds**, then average the results of out-of-sample performance evaluation applied to each combination of a model constructed from data not in a fold and predictions made about data that are in that fold.  It is assumed that such models on average have performance closely approximating that of the model to be evaluated.  This method has the advantage that the models taken together are constructed from all the data, and further has the advantage that predictions made by any particular model are about data not know to that model.\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px\">\n",
    "    <caption style=\"text-align:center\">Cross-Validation Evaluation of a Classifier</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"classification_xval.jpg\" width=950></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "<table style=\"border:1px solid; margin-top:20px; margin-bottom:20px\">\n",
    "    <caption style=\"text-align:center\">Cross-Validation Evaluation of a Regressorr</caption>\n",
    "    <tr><td style=\"padding:20px; background-color:white\"><img src=\"regression_xval.jpg\" width=950></td></tr>\n",
    "</table><br clear=all>\n",
    "\n",
    "\n",
    "#### Classifier Performance Metrics\n",
    "\n",
    "The **confusion matrix** for some predictive model, dataset, and cutoff threshold indicates the relationships between how the model would predict classes and the known actual classes.  For a binary classifier, the confusion matrix is 2x2 comprising four counts of predictions: predicted positive class that are actually positive class, predicted positive class that are actually negative class, predicted negative class that are actually positive class, and predicted negative class that are actually negative class.\n",
    "\n",
    "Classifier performance metrics are calculated from values in a confusion matrix.  Here are some popular classifier performance metrics:\n",
    "* accuracy (correct prediction rate)\n",
    "* true positive rate (sensitivity, recall)\n",
    "* true negative rate (aka specificity)\n",
    "* false positive rate\n",
    "* false negative rate\n",
    "* positive predictive value (aka precision)\n",
    "* negative predictive value\n",
    "* f1 score\n",
    "<br><br>\n",
    "* business performance, calculated per a decision model\n",
    "<br><br>\n",
    "\n",
    "\n",
    "#### Regressor Performance Metrics\n",
    "\n",
    "The **error table** for some model and dataset indicates the relationship between how the model would predict outcomes and the known actual outcomes.\n",
    "\n",
    "Regressor performance metrics are calculated from an error table.  Here are some popular regressor performance metrics:\n",
    "* root mean square error (RMSE)\n",
    "* mean absolute percent error (MAPE)\n",
    "<br><br>\n",
    "* business performance, calculated per a decision model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning Methods\n",
    "\n",
    "**Model tuning** is systematically exploring the effects of method, variables, hyper-parameter settings, and cutoff settings on model performance to determine the best combination.  \n",
    "\n",
    "Here are three popular ways to explore the effects of variables on model performance:\n",
    "\n",
    "* **Forward feature selection** does so by evaluating the effect of using each variable individually, keeping the best variable, and then proceeding to evaluate the effects of remaining possible pairs, triples, etc.\n",
    "* **Backward feature selection** does so by evaluating the effect of each set of variables less one, keeping the best set, and then proceeding to evaluate the effects of successive sets of variables less one.\n",
    "* **Exhaustive feature selection** does so by evaluating the effect of each possible combination of variables.  \n",
    "\n",
    "Often, principal component analysis is used in combination with forward feature selection to reduce the number of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technology\n",
    "\n",
    "R and Python are popular open-source programming languages often used for exploratory data analysis and modeling.  Both languages can be executed within special interactive development environments (IDE) or within a Jupyter notebook running on a local machine or JupyterHub server. \n",
    "\n",
    "SQL is a popular query language often used for data extraction and some other aspects of exploratory data analysis.\n",
    "\n",
    "Microsoft Excel is a commercial spreadsheet product often used for data analysis and modeling.\n",
    "\n",
    "SAS, JMP, IBM SPSS, Tableau, and other products provide convenient user interfaces to exploratory data analysis and modeling functionality, without necessarily requiring programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:left; font-size:10px;\">\n",
    "Copyright (c) Berkeley Data Analytics Group, LLC\n",
    "<span style=\"float:right;\">\n",
    "Document revised July 18, 2020\n",
    "</span>\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "hide_input": true,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1131.32px",
    "left": "651px",
    "top": "110px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
